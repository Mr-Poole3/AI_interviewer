"""
LLMé¢è¯•å®˜FastAPIåç«¯æœåŠ¡

åŸºäºAzure OpenAIå®æ—¶è¯­éŸ³æ¨¡å‹çš„æ™ºèƒ½é¢è¯•ç³»ç»Ÿ
æ”¯æŒæ–‡æœ¬èŠå¤©ã€è¯­éŸ³è¾“å…¥è¾“å‡ºå’Œç®€å†ä¸Šä¼ åŠŸèƒ½
"""
import json
import logging
import os
import tempfile
import io
import base64
import hashlib
import asyncio
from typing import Dict, List, Optional, Any
from pathlib import Path

from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException, UploadFile, File
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import uvicorn

# æ–‡ä»¶è§£æåº“
import PyPDF2
from docx import Document

# Azure OpenAIå®æ—¶è¯­éŸ³å®¢æˆ·ç«¯
from openai import AsyncAzureOpenAI

# å¯¼å…¥æç¤ºè¯é…ç½®
from prompts import get_interviewer_prompt, get_voice_call_prompt

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

app = FastAPI(title="Azureè¯­éŸ³é¢è¯•å®˜ç³»ç»Ÿ", description="åŸºäºAzure OpenAIå®æ—¶è¯­éŸ³æ¨¡å‹çš„æ™ºèƒ½é¢è¯•ç³»ç»Ÿ")

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æŒ‚è½½é™æ€æ–‡ä»¶
app.mount("/static", StaticFiles(directory="static"), name="static")


class AzureVoiceService:
    """Azureè¯­éŸ³æœåŠ¡ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–Azureè¯­éŸ³æœåŠ¡"""
        self.client: Optional[AsyncAzureOpenAI] = None
        self._init_client()
    
    def _init_client(self) -> None:
        """åˆå§‹åŒ–Azure OpenAIå®¢æˆ·ç«¯"""
        try:
            # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
            azure_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT", "https://gpt-realtime-4o-mini.openai.azure.com")
            api_key = os.getenv("AZURE_OPENAI_API_KEY")
            api_version = os.getenv("AZURE_API_VERSION", "2025-04-01-preview")
            
            if not api_key:
                logger.error("Azure OpenAI APIå¯†é’¥æœªè®¾ç½®ï¼")
                return
            
            self.client = AsyncAzureOpenAI(
                azure_endpoint=azure_endpoint,
                api_key=api_key,
                api_version=api_version,
            )
            logger.info("Azure OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"Azure OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
    
    async def chat_with_voice(self, message: str, websocket: WebSocket, resume_context: str = "") -> None:
        """
        å‘é€æ¶ˆæ¯å¹¶æ¥æ”¶è¯­éŸ³å›å¤
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            websocket: WebSocketè¿æ¥
            resume_context: ç®€å†ä¸Šä¸‹æ–‡
        """
        if not self.client:
            await websocket.send_json({
                "type": "error",
                "message": "Azureå®¢æˆ·ç«¯æœªåˆå§‹åŒ–"
            })
            return
        
        try:
            async with self.client.beta.realtime.connect(
                model="gpt-4o-mini-realtime-preview"
            ) as connection:
                # é…ç½®ä¼šè¯æ”¯æŒæ–‡æœ¬å’ŒéŸ³é¢‘
                await connection.session.update(
                    session={"modalities": ["text", "audio"]}
                )
                
                # æ„å»ºç³»ç»Ÿæç¤ºè¯
                system_prompt = self._build_system_prompt(resume_context)
                
                # å‘é€ç³»ç»Ÿæ¶ˆæ¯ï¼ˆå¦‚æœæœ‰ç®€å†ä¸Šä¸‹æ–‡ï¼‰
                if resume_context:
                    await connection.conversation.item.create(
                        item={
                            "type": "message",
                            "role": "system",
                            "content": [{"type": "input_text", "text": system_prompt}],
                        }
                    )
                
                # å‘é€ç”¨æˆ·æ¶ˆæ¯
                await connection.conversation.item.create(
                    item={
                        "type": "message",
                        "role": "user",
                        "content": [{"type": "input_text", "text": message}],
                    }
                )
                
                # è¯·æ±‚å›å¤
                await connection.response.create()
                
                # å¤„ç†å“åº”äº‹ä»¶
                async for event in connection:
                    await self._handle_response_event(event, websocket)
                    
                    if event.type == "response.done":
                        break
                        
        except Exception as e:
            logger.error(f"è¯­éŸ³èŠå¤©é”™è¯¯: {e}")
            await websocket.send_json({
                "type": "error",
                "message": f"è¯­éŸ³èŠå¤©é”™è¯¯: {str(e)}"
            })
    
    def _build_system_prompt(self, resume_context: str) -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
        return get_interviewer_prompt(resume_context=resume_context)
    
    async def _handle_response_event(self, event: Any, websocket: WebSocket) -> None:
        """
        å¤„ç†å“åº”äº‹ä»¶
        
        Args:
            event: å“åº”äº‹ä»¶
            websocket: WebSocketè¿æ¥
        """
        try:
            if event.type == "response.text.delta":
                # æ–‡æœ¬å¢é‡
                await websocket.send_json({
                    "type": "text_delta",
                    "content": event.delta
                })
                
            elif event.type == "response.audio.delta":
                # éŸ³é¢‘å¢é‡ - å‘é€base64ç¼–ç çš„éŸ³é¢‘æ•°æ®
                await websocket.send_json({
                    "type": "audio_delta",
                    "audio_data": event.delta,  # å·²ç»æ˜¯base64ç¼–ç 
                    "content_type": "audio/pcm"
                })
                
            elif event.type == "response.audio_transcript.delta":
                # éŸ³é¢‘è½¬å½•å¢é‡
                await websocket.send_json({
                    "type": "transcript_delta",
                    "content": event.delta
                })
                
            elif event.type == "response.text.done":
                # æ–‡æœ¬å®Œæˆ
                await websocket.send_json({
                    "type": "text_done"
                })
                
            elif event.type == "response.audio.done":
                # éŸ³é¢‘å®Œæˆ
                await websocket.send_json({
                    "type": "audio_done"
                })
                
            elif event.type == "response.done":
                # å“åº”å®Œæˆ
                await websocket.send_json({
                    "type": "response_done"
                })
                
        except Exception as e:
            logger.error(f"å¤„ç†å“åº”äº‹ä»¶é”™è¯¯: {e}")

    async def process_fastrtc_audio(
        self, 
        audio_data: str, 
        websocket: WebSocket, 
        resume_context: str = "",
        audio_format: str = "pcm_s16le",
        sample_rate: int = 24000,
        channels: int = 1,
        vad_confidence: float = 0.0
    ) -> None:
        """
        å¤„ç†FastRTCå¢å¼ºçš„éŸ³é¢‘æ•°æ®
        
        Args:
            audio_data: base64ç¼–ç çš„éŸ³é¢‘æ•°æ®
            websocket: WebSocketè¿æ¥
            resume_context: ç®€å†ä¸Šä¸‹æ–‡
            audio_format: éŸ³é¢‘æ ¼å¼
            sample_rate: é‡‡æ ·ç‡
            channels: å£°é“æ•°
            vad_confidence: è¯­éŸ³æ´»åŠ¨æ£€æµ‹ç½®ä¿¡åº¦
        """
        if not self.client:
            await websocket.send_json({
                "type": "error",
                "message": "Azureå®¢æˆ·ç«¯æœªåˆå§‹åŒ–"
            })
            return
        
        try:
            # è§£ç base64éŸ³é¢‘æ•°æ®
            audio_bytes = base64.b64decode(audio_data)
            
            # è®°å½•éŸ³é¢‘è´¨é‡ä¿¡æ¯
            logger.info(f"æ”¶åˆ°FastRTCéŸ³é¢‘æ•°æ®: æ ¼å¼={audio_format}, é‡‡æ ·ç‡={sample_rate}, VADç½®ä¿¡åº¦={vad_confidence:.3f}")
            
            # è°ƒæ•´VADç½®ä¿¡åº¦é˜ˆå€¼æ£€æŸ¥ - åŸé˜ˆå€¼0.01è¿‡äºä¸¥æ ¼
            # ä½¿ç”¨æ›´ä½çš„é˜ˆå€¼ï¼Œå¹¶è€ƒè™‘éŸ³é¢‘æ•°æ®é•¿åº¦
            min_vad_threshold = 0.001  # é™ä½åŸºç¡€é˜ˆå€¼
            
            # å¦‚æœéŸ³é¢‘æ•°æ®è¶³å¤Ÿé•¿ï¼Œå³ä½¿VADç½®ä¿¡åº¦è¾ƒä½ä¹Ÿå¯ä»¥å¤„ç†
            audio_duration_ms = (len(audio_bytes) / 2) / sample_rate * 1000  # è®¡ç®—éŸ³é¢‘æ—¶é•¿(ms)
            
            # åŠ¨æ€è°ƒæ•´é˜ˆå€¼ï¼šéŸ³é¢‘è¶Šé•¿ï¼Œå…è®¸çš„VADé˜ˆå€¼è¶Šä½
            if audio_duration_ms > 200:  # è¶…è¿‡200msçš„éŸ³é¢‘
                dynamic_threshold = max(0.0005, min_vad_threshold * 0.5)
            elif audio_duration_ms > 100:  # è¶…è¿‡100msçš„éŸ³é¢‘
                dynamic_threshold = max(0.001, min_vad_threshold * 0.8)
            else:
                dynamic_threshold = min_vad_threshold
            
            if vad_confidence < dynamic_threshold:
                logger.debug(f"VADç½®ä¿¡åº¦({vad_confidence:.4f})ä½äºåŠ¨æ€é˜ˆå€¼({dynamic_threshold:.4f})ï¼Œ"
                           f"éŸ³é¢‘æ—¶é•¿{audio_duration_ms:.1f}msï¼Œè·³è¿‡éŸ³é¢‘å¤„ç†")
                return
            
            logger.info(f"é€šè¿‡VADæ£€æŸ¥ï¼Œå¼€å§‹å¤„ç†éŸ³é¢‘: ç½®ä¿¡åº¦={vad_confidence:.4f}, "
                       f"é˜ˆå€¼={dynamic_threshold:.4f}, æ—¶é•¿={audio_duration_ms:.1f}ms")
            
            async with self.client.beta.realtime.connect(
                model="gpt-4o-mini-realtime-preview"
            ) as connection:
                # é…ç½®ä¼šè¯æ”¯æŒéŸ³é¢‘è¾“å…¥
                await connection.session.update(
                    session={
                        "modalities": ["text", "audio"],
                        "input_audio_format": "pcm16",  # Azureæ”¯æŒçš„æ ¼å¼
                        "output_audio_format": "pcm16",
                        "input_audio_transcription": {
                            "model": "whisper-1"
                        }
                    }
                )
                
                # æ„å»ºç³»ç»Ÿæç¤ºè¯
                if resume_context:
                    system_prompt = self._build_system_prompt(resume_context)
                    await connection.conversation.item.create(
                        item={
                            "type": "message",
                            "role": "system",
                            "content": [{"type": "input_text", "text": system_prompt}],
                        }
                    )
                
                # å‘é€éŸ³é¢‘æ•°æ®
                await connection.input_audio_buffer.append(audio=audio_data)
                
                # æäº¤éŸ³é¢‘è¾“å…¥
                await connection.input_audio_buffer.commit()
                
                # è¯·æ±‚å›å¤
                await connection.response.create()
                
                # å¤„ç†å“åº”äº‹ä»¶
                async for event in connection:
                    await self._handle_response_event(event, websocket)
                    
                    if event.type == "response.done":
                        break
                        
        except Exception as e:
            logger.error(f"FastRTCéŸ³é¢‘å¤„ç†é”™è¯¯: {e}")
            await websocket.send_json({
                "type": "error",
                "message": f"éŸ³é¢‘å¤„ç†é”™è¯¯: {str(e)}"
            })


# å…¨å±€Azureè¯­éŸ³æœåŠ¡å®ä¾‹
azure_voice_service: AzureVoiceService = None

# å­˜å‚¨ç”¨æˆ·ä¼šè¯çš„ç®€å†å†…å®¹
user_sessions: Dict[str, str] = {}

# ç®€å†å­˜å‚¨ç›®å½•
RESUME_STORAGE_DIR = Path("resume_storage")
RESUME_STORAGE_DIR.mkdir(exist_ok=True)

def save_resume_to_file(resume_text: str, session_id: str) -> bool:
    """
    å°†ç®€å†æ–‡æœ¬ä¿å­˜åˆ°æ–‡ä»¶
    
    Args:
        resume_text: ç®€å†æ–‡æœ¬å†…å®¹
        session_id: ä¼šè¯ID
        
    Returns:
        ä¿å­˜æ˜¯å¦æˆåŠŸ
    """
    try:
        resume_file = RESUME_STORAGE_DIR / f"{session_id}.txt"
        with open(resume_file, 'w', encoding='utf-8') as f:
            f.write(resume_text)
        logger.info(f"ç®€å†å·²ä¿å­˜åˆ°æ–‡ä»¶: {resume_file}")
        return True
    except Exception as e:
        logger.error(f"ä¿å­˜ç®€å†æ–‡ä»¶å¤±è´¥: {e}")
        return False

def load_resume_from_file(session_id: str) -> Optional[str]:
    """
    ä»æ–‡ä»¶åŠ è½½ç®€å†æ–‡æœ¬
    
    Args:
        session_id: ä¼šè¯ID
        
    Returns:
        ç®€å†æ–‡æœ¬å†…å®¹ï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨åˆ™è¿”å›None
    """
    try:
        resume_file = RESUME_STORAGE_DIR / f"{session_id}.txt"
        if resume_file.exists():
            with open(resume_file, 'r', encoding='utf-8') as f:
                content = f.read()
            logger.info(f"ä»æ–‡ä»¶åŠ è½½ç®€å†: {resume_file}")
            return content
        return None
    except Exception as e:
        logger.error(f"åŠ è½½ç®€å†æ–‡ä»¶å¤±è´¥: {e}")
        return None

def generate_resume_hash(resume_text: str) -> str:
    """
    ç”Ÿæˆç®€å†å†…å®¹çš„å“ˆå¸Œå€¼ï¼Œç”¨äºå»é‡å’ŒéªŒè¯
    
    Args:
        resume_text: ç®€å†æ–‡æœ¬å†…å®¹
        
    Returns:
        ç®€å†å†…å®¹çš„MD5å“ˆå¸Œå€¼
    """
    return hashlib.md5(resume_text.encode('utf-8')).hexdigest()[:16]

def extract_pdf_text(file_content: bytes) -> str:
    """
    ä»PDFæ–‡ä»¶å†…å®¹ä¸­æå–æ–‡æœ¬
    
    Args:
        file_content: PDFæ–‡ä»¶çš„å­—èŠ‚å†…å®¹
        
    Returns:
        æå–å‡ºçš„æ–‡æœ¬å†…å®¹
    """
    try:
        pdf_file = io.BytesIO(file_content)
        reader = PyPDF2.PdfReader(pdf_file)
        text = ""
        
        for page in reader.pages:
            page_text = page.extract_text()
            if page_text:
                text += page_text + "\n"
        
        return text.strip()
    except Exception as e:
        logger.error(f"PDFè§£æå¤±è´¥: {e}")
        raise HTTPException(status_code=400, detail=f"PDFæ–‡ä»¶è§£æå¤±è´¥: {str(e)}")

def extract_docx_text(file_content: bytes) -> str:
    """
    ä»Wordæ–‡æ¡£å†…å®¹ä¸­æå–æ–‡æœ¬
    
    Args:
        file_content: Wordæ–‡æ¡£çš„å­—èŠ‚å†…å®¹
        
    Returns:
        æå–å‡ºçš„æ–‡æœ¬å†…å®¹
    """
    try:
        docx_file = io.BytesIO(file_content)
        doc = Document(docx_file)
        text = ""
        
        for paragraph in doc.paragraphs:
            if paragraph.text.strip():
                text += paragraph.text + "\n"
        
        return text.strip()
    except Exception as e:
        logger.error(f"Wordæ–‡æ¡£è§£æå¤±è´¥: {e}")
        raise HTTPException(status_code=400, detail=f"Wordæ–‡æ¡£è§£æå¤±è´¥: {str(e)}")

def validate_file(file: UploadFile) -> None:
    """
    éªŒè¯ä¸Šä¼ çš„æ–‡ä»¶
    
    Args:
        file: ä¸Šä¼ çš„æ–‡ä»¶å¯¹è±¡
    """
    # æ£€æŸ¥æ–‡ä»¶å¤§å° (æœ€å¤§10MB)
    max_size = 10 * 1024 * 1024  # 10MB
    
    # æ£€æŸ¥æ–‡ä»¶ç±»å‹
    allowed_extensions = {'.pdf', '.doc', '.docx'}
    allowed_mime_types = {
        'application/pdf',
        'application/msword',
        'application/vnd.openxmlformats-officedocument.wordprocessingml.document'
    }
    
    if not file.filename:
        raise HTTPException(status_code=400, detail="æ–‡ä»¶åä¸èƒ½ä¸ºç©º")
    
    file_extension = Path(file.filename).suffix.lower()
    if file_extension not in allowed_extensions:
        raise HTTPException(
            status_code=400, 
            detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ã€‚æ”¯æŒçš„æ ¼å¼: {', '.join(allowed_extensions)}"
        )
    
    if file.content_type not in allowed_mime_types:
        logger.warning(f"æ–‡ä»¶MIMEç±»å‹æ£€æŸ¥: {file.content_type}")
        # ä¸å¼ºåˆ¶æ£€æŸ¥MIMEç±»å‹ï¼Œå› ä¸ºæœ‰äº›æµè§ˆå™¨å¯èƒ½å‘é€ä¸å‡†ç¡®çš„ç±»å‹

@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶çš„åˆå§‹åŒ–"""
    global azure_voice_service
    try:
        azure_voice_service = AzureVoiceService()
        logger.info("Azureè¯­éŸ³æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
    except Exception as e:
        logger.error(f"Azureè¯­éŸ³æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")

@app.get("/")
async def read_root():
    """è¿”å›ä¸»é¡µé¢"""
    return FileResponse("static/index.html")

from pydantic import BaseModel

class PromptRequest(BaseModel):
    resume_context: str = ""

@app.post("/api/prompts/voice-call")
async def get_voice_call_prompt_api(request: PromptRequest) -> JSONResponse:
    """
    è·å–è¯­éŸ³é€šè¯ä¸“ç”¨prompt
    
    Args:
        request: åŒ…å«resume_contextçš„è¯·æ±‚ä½“
        
    Returns:
        promptæŒ‡ä»¤
    """
    try:
        resume_context = request.resume_context
        instructions = get_voice_call_prompt(resume_context=resume_context)
        
        return JSONResponse(content={
            "success": True,
            "instructions": instructions,
            "has_resume": bool(resume_context)
        })
        
    except Exception as e:
        logger.error(f"è·å–è¯­éŸ³é€šè¯promptå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}")

@app.get("/api/prompts/voice-call-default")
async def get_voice_call_default_prompt() -> JSONResponse:
    """
    è·å–è¯­éŸ³é€šè¯çš„é»˜è®¤promptï¼ˆä¸åŒ…å«ç®€å†ä¸Šä¸‹æ–‡ï¼‰
    
    Returns:
        é»˜è®¤çš„è¯­éŸ³é€šè¯prompt
    """
    try:
        from prompts import InterviewPrompts
        
        return JSONResponse(content={
            "success": True,
            "instructions": InterviewPrompts.VOICE_CALL_INTERVIEWER,
            "source": "prompts.py - VOICE_CALL_INTERVIEWER"
        })
        
    except Exception as e:
        logger.error(f"è·å–é»˜è®¤è¯­éŸ³é€šè¯promptå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}")

@app.get("/api/prompts/list")
async def list_prompts() -> JSONResponse:
    """
    åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„promptç±»å‹
    
    Returns:
        promptç±»å‹åˆ—è¡¨
    """
    try:
        from prompts import InterviewPrompts, SystemPrompts, UIPrompts, NotificationPrompts
        
        prompt_info = {
            "interview_prompts": {
                "base_interviewer": InterviewPrompts.BASE_INTERVIEWER,
                "voice_call_interviewer": InterviewPrompts.VOICE_CALL_INTERVIEWER,
                "position_specific": list(InterviewPrompts.POSITION_SPECIFIC.keys())
            },
            "system_prompts": {
                "welcome_message": SystemPrompts.WELCOME_MESSAGE,
                "error_messages": list(SystemPrompts.ERROR_MESSAGES.keys()),
                "status_messages": list(SystemPrompts.STATUS_MESSAGES.keys())
            },
            "ui_prompts": {
                "button_texts": list(UIPrompts.BUTTON_TEXTS.keys()),
                "placeholders": list(UIPrompts.PLACEHOLDERS.keys()),
                "hints": list(UIPrompts.HINTS.keys())
            },
            "notification_prompts": {
                "success_messages": list(NotificationPrompts.SUCCESS_MESSAGES.keys()),
                "warning_messages": list(NotificationPrompts.WARNING_MESSAGES.keys()),
                "error_messages": list(NotificationPrompts.ERROR_MESSAGES.keys())
            }
        }
        
        return JSONResponse(content={
            "success": True,
            "prompts": prompt_info,
            "message": "æ‰€æœ‰prompté…ç½®å·²ä»prompts.pyæ–‡ä»¶ä¸­é›†ä¸­ç®¡ç†"
        })
        
    except Exception as e:
        logger.error(f"è·å–promptåˆ—è¡¨å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}")

@app.get("/api/prompts/validate")
async def validate_prompt_management() -> JSONResponse:
    """
    éªŒè¯promptç®¡ç†æ˜¯å¦å®Œå…¨é€šè¿‡prompts.pyæ–‡ä»¶
    
    Returns:
        éªŒè¯ç»“æœå’Œå»ºè®®
    """
    try:
        from prompts import InterviewPrompts, SystemPrompts, UIPrompts, NotificationPrompts
        
        validation_result = {
            "prompts_py_status": "âœ… prompts.pyæ–‡ä»¶æ­£å¸¸åŠ è½½",
            "centralized_management": True,
            "available_prompts": {
                "interview_prompts": len(InterviewPrompts.POSITION_SPECIFIC) + 2,  # BASE + VOICE_CALL + positions
                "system_prompts": len(SystemPrompts.ERROR_MESSAGES) + len(SystemPrompts.STATUS_MESSAGES) + 1,  # + WELCOME
                "ui_prompts": len(UIPrompts.BUTTON_TEXTS) + len(UIPrompts.PLACEHOLDERS) + len(UIPrompts.HINTS),
                "notification_prompts": len(NotificationPrompts.SUCCESS_MESSAGES) + len(NotificationPrompts.WARNING_MESSAGES) + len(NotificationPrompts.ERROR_MESSAGES)
            },
            "api_endpoints": [
                "/api/prompts/voice-call - è·å–è¯­éŸ³é€šè¯promptï¼ˆå¸¦ç®€å†ä¸Šä¸‹æ–‡ï¼‰",
                "/api/prompts/voice-call-default - è·å–é»˜è®¤è¯­éŸ³é€šè¯prompt",
                "/api/prompts/list - åˆ—å‡ºæ‰€æœ‰promptç±»å‹",
                "/api/prompts/validate - éªŒè¯promptç®¡ç†çŠ¶æ€"
            ],
            "recommendations": [
                "âœ… æ‰€æœ‰promptå·²é€šè¿‡prompts.pyé›†ä¸­ç®¡ç†",
                "âœ… å‰ç«¯å·²é…ç½®APIå›é€€æœºåˆ¶",
                "âœ… æ”¯æŒåŠ¨æ€promptæ›´æ–°",
                "ğŸ’¡ å»ºè®®å®šæœŸå®¡æŸ¥promptå†…å®¹çš„ä¸“ä¸šæ€§å’Œå‡†ç¡®æ€§"
            ]
        }
        
        return JSONResponse(content={
            "success": True,
            "validation": validation_result,
            "message": "Promptç®¡ç†éªŒè¯å®Œæˆ - æ‰€æœ‰é…ç½®å·²é›†ä¸­åˆ°prompts.py"
        })
        
    except Exception as e:
        logger.error(f"Promptç®¡ç†éªŒè¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}")

@app.get("/api/resume/{session_id}")
async def get_resume_content(session_id: str) -> JSONResponse:
    """
    è·å–æŒ‡å®šä¼šè¯çš„ç®€å†å†…å®¹
    
    Args:
        session_id: ä¼šè¯ID
        
    Returns:
        ç®€å†å†…å®¹
    """
    try:
        # ä»å†…å­˜æˆ–æ–‡ä»¶è·å–ç®€å†å†…å®¹
        resume_content = user_sessions.get(session_id) or load_resume_from_file(session_id)
        
        if not resume_content:
            raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°å¯¹åº”çš„ç®€å†å†…å®¹")
        
        return JSONResponse(content={
            "success": True,
            "session_id": session_id,
            "content": resume_content,
            "content_length": len(resume_content)
        })
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–ç®€å†å†…å®¹å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}")

@app.post("/api/upload-resume")
async def upload_resume(file: UploadFile = File(...)) -> JSONResponse:
    """
    ä¸Šä¼ å¹¶è§£æç®€å†æ–‡ä»¶
    
    Args:
        file: ä¸Šä¼ çš„ç®€å†æ–‡ä»¶
        
    Returns:
        è§£æç»“æœå’Œä¼šè¯ID
    """
    try:
        # éªŒè¯æ–‡ä»¶
        validate_file(file)
        
        # è¯»å–æ–‡ä»¶å†…å®¹
        file_content = await file.read()
        
        # æ ¹æ®æ–‡ä»¶ç±»å‹è§£ææ–‡æœ¬
        file_extension = Path(file.filename).suffix.lower()
        
        if file_extension == '.pdf':
            resume_text = extract_pdf_text(file_content)
        elif file_extension in ['.doc', '.docx']:
            resume_text = extract_docx_text(file_content)
        else:
            raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼")
        
        # éªŒè¯è§£æç»“æœ
        if not resume_text or len(resume_text.strip()) < 50:
            raise HTTPException(status_code=400, detail="ç®€å†å†…å®¹è¿‡å°‘æˆ–è§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶å†…å®¹")
        
        # ç”Ÿæˆä¼šè¯ID
        session_id = generate_resume_hash(resume_text)
        
        # ä¿å­˜ç®€å†å†…å®¹
        user_sessions[session_id] = resume_text
        save_resume_to_file(resume_text, session_id)
        
        logger.info(f"ç®€å†ä¸Šä¼ æˆåŠŸ: {file.filename}, ä¼šè¯ID: {session_id}, å†…å®¹é•¿åº¦: {len(resume_text)}")
        
        return JSONResponse(content={
            "success": True,
            "message": "ç®€å†ä¸Šä¼ å¹¶è§£ææˆåŠŸ",
            "session_id": session_id,
            "filename": file.filename,
            "content_length": len(resume_text),
            "preview": resume_text[:200] + "..." if len(resume_text) > 200 else resume_text
        })
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ç®€å†ä¸Šä¼ å¤„ç†å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}")

@app.websocket("/ws/voice")
async def websocket_voice_endpoint(websocket: WebSocket):
    """Azureè¯­éŸ³èŠå¤©WebSocketç«¯ç‚¹ - FastRTCå¢å¼ºç‰ˆ"""
    await websocket.accept()
    logger.info("Azureè¯­éŸ³WebSocketè¿æ¥å·²å»ºç«‹ - FastRTCå¢å¼ºæ¨¡å¼")
    
    # å­˜å‚¨å½“å‰æ´»è·ƒçš„Azureè¿æ¥ï¼Œç”¨äºæ‰“æ–­å¤„ç†
    current_azure_connection = None
    
    try:
        while True:
            # æ¥æ”¶æ¶ˆæ¯
            data = await websocket.receive_json()
            message_type = data.get("type")
            
            if message_type == "chat":
                message = data.get("message", "")
                session_id = data.get("session_id", "")
                
                if message.strip():
                    logger.info(f"æ”¶åˆ°è¯­éŸ³èŠå¤©æ¶ˆæ¯: {message}")
                    
                    # è·å–ç®€å†ä¸Šä¸‹æ–‡
                    resume_context = ""
                    if session_id:
                        resume_context = user_sessions.get(session_id) or load_resume_from_file(session_id)
                    
                    await azure_voice_service.chat_with_voice(message, websocket, resume_context)
                    
            elif message_type == "voice_input":
                # FastRTCå¢å¼ºçš„è¯­éŸ³è¾“å…¥å¤„ç†
                audio_data = data.get("audio_data", "")
                audio_format = data.get("audio_format", "pcm_s16le")
                sample_rate = data.get("sample_rate", 24000)
                channels = data.get("channels", 1)
                vad_confidence = data.get("vad_confidence", 0.0)
                session_id = data.get("session_id", "")
                
                if audio_data:
                    logger.info(f"æ”¶åˆ°FastRTCéŸ³é¢‘æ•°æ®: æ ¼å¼={audio_format}, é‡‡æ ·ç‡={sample_rate}, VADç½®ä¿¡åº¦={vad_confidence:.3f}")
                    
                    # è·å–ç®€å†ä¸Šä¸‹æ–‡
                    resume_context = ""
                    if session_id:
                        resume_context = user_sessions.get(session_id) or load_resume_from_file(session_id)
                    
                    # å¤„ç†FastRTCéŸ³é¢‘è¾“å…¥
                    await azure_voice_service.process_fastrtc_audio(
                        audio_data, 
                        websocket, 
                        resume_context,
                        audio_format=audio_format,
                        sample_rate=sample_rate,
                        channels=channels,
                        vad_confidence=vad_confidence
                    )
                    
            elif message_type == "interrupt_request":
                # å¤„ç†æ‰“æ–­è¯·æ±‚
                session_id = data.get("session_id", "")
                reason = data.get("reason", "user_request")
                timestamp = data.get("timestamp", 0)
                
                logger.info(f"æ”¶åˆ°æ‰“æ–­è¯·æ±‚: ä¼šè¯ID={session_id}, åŸå› ={reason}, æ—¶é—´æˆ³={timestamp}")
                
                # ä¸­æ–­å½“å‰Azureè¿æ¥ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if current_azure_connection:
                    try:
                        # è¿™é‡Œå¯ä»¥æ·»åŠ å…·ä½“çš„è¿æ¥ä¸­æ–­é€»è¾‘
                        # Azureå®æ—¶APIå¯èƒ½éœ€è¦ç‰¹å®šçš„ä¸­æ–­æ–¹æ³•
                        logger.info("æ­£åœ¨ä¸­æ–­Azureè¿æ¥...")
                        current_azure_connection = None
                    except Exception as e:
                        logger.error(f"ä¸­æ–­Azureè¿æ¥å¤±è´¥: {e}")
                
                # å‘é€æ‰“æ–­ç¡®è®¤
                await websocket.send_json({
                    "type": "interrupt_acknowledged",
                    "session_id": session_id,
                    "timestamp": timestamp,
                    "reason": reason,
                    "message": "æ‰“æ–­è¯·æ±‚å·²å¤„ç†"
                })
                
                logger.info(f"æ‰“æ–­è¯·æ±‚å¤„ç†å®Œæˆ: ä¼šè¯ID={session_id}")
                    
            elif message_type == "voice_input_end":
                # è¯­éŸ³è¾“å…¥ç»“æŸ
                session_id = data.get("session_id", "")
                logger.info(f"è¯­éŸ³è¾“å…¥ç»“æŸ: ä¼šè¯ID={session_id}")
                
                await websocket.send_json({
                    "type": "voice_input_complete",
                    "message": "è¯­éŸ³è¾“å…¥å¤„ç†å®Œæˆ"
                })
                
            elif message_type == "ping":
                await websocket.send_json({"type": "pong"})
                
    except WebSocketDisconnect:
        logger.info("Azureè¯­éŸ³WebSocketè¿æ¥å·²æ–­å¼€")
    except Exception as e:
        logger.error(f"Azureè¯­éŸ³WebSocketé”™è¯¯: {e}")
        try:
            await websocket.send_json({
                "type": "error",
                "message": f"æœåŠ¡å™¨é”™è¯¯: {str(e)}"
            })
        except:
            pass

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {
        "status": "healthy", 
        "service": "Azure Voice Interview System",
        "azure_client_ready": azure_voice_service.client is not None if azure_voice_service else False
    }

if __name__ == "__main__":
    
    print("ğŸš€ å¯åŠ¨Azureè¯­éŸ³é¢è¯•å®˜ç³»ç»Ÿ...")
    print("ğŸ“¡ æœåŠ¡åœ°å€: http://localhost:8000")
    print("ğŸ¤ æ”¯æŒå®æ—¶è¯­éŸ³é¢è¯•åŠŸèƒ½")
    
    uvicorn.run(
        app,
        host="localhost",
        port=8000,
        reload=True,
        log_level="info"
    ) 