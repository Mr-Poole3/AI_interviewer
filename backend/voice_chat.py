"""
å®æ—¶è¯­éŸ³äº¤äº’æ¨¡å—

åŸºäºFastRTCå’ŒGoogle Geminiè¯­éŸ³APIçš„å®æ—¶è¯­éŸ³å¯¹è¯ç³»ç»Ÿ
æ”¯æŒè¯­éŸ³è¾“å…¥ã€æš‚åœæ£€æµ‹ã€å®æ—¶å“åº”å’Œè¯­éŸ³è¾“å‡º
"""
import logging
import asyncio
from typing import Optional, AsyncGenerator, Tuple
import numpy as np
import google.generativeai as genai
from fastrtc import Stream, ReplyOnPause, audio_to_bytes, aggregate_bytes_to_16bit
import io
import wave

# å¯¼å…¥é¡¹ç›®é…ç½®
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config import get_GEMINI_API_KEY, get_gemini_model

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class GeminiVoiceChat:
    """
    Geminiè¯­éŸ³èŠå¤©å®¢æˆ·ç«¯
    
    æä¾›å®æ—¶è¯­éŸ³äº¤äº’åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
    - è¯­éŸ³è½¬æ–‡å­—ï¼ˆé€šè¿‡Gemini Live APIï¼‰
    - æ™ºèƒ½å¯¹è¯ç”Ÿæˆ
    - æ–‡å­—è½¬è¯­éŸ³è¾“å‡º
    - è‡ªåŠ¨æš‚åœæ£€æµ‹
    """
    
    def __init__(self, api_key: Optional[str] = None, model_name: Optional[str] = None):
        """
        åˆå§‹åŒ–Geminiè¯­éŸ³èŠå¤©å®¢æˆ·ç«¯
        
        Args:
            api_key: Google AI APIå¯†é’¥
            model_name: Geminiæ¨¡å‹åç§°
        """
        self.api_key = api_key or get_GEMINI_API_KEY()
        self.model_name = model_name or get_gemini_model()
        
        if not self.api_key:
            raise ValueError("Google AI APIå¯†é’¥æœªè®¾ç½®ï¼Œè¯·è®¾ç½®GEMINI_API_KEYç¯å¢ƒå˜é‡")
        
        # é…ç½®Google AI
        genai.configure(api_key=self.api_key)
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = genai.GenerativeModel(self.model_name)
        
        # å¯¹è¯å†å²
        self.chat_history = []
        
        logger.info(f"Geminiè¯­éŸ³èŠå¤©å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆï¼Œæ¨¡å‹: {self.model_name}")
    
    def _audio_to_wav_bytes(self, audio_data: Tuple[int, np.ndarray]) -> bytes:
        """
        å°†éŸ³é¢‘æ•°æ®è½¬æ¢ä¸ºWAVæ ¼å¼å­—èŠ‚æµ
        
        Args:
            audio_data: (é‡‡æ ·ç‡, éŸ³é¢‘æ•°ç»„) å…ƒç»„
            
        Returns:
            WAVæ ¼å¼çš„å­—èŠ‚æµ
        """
        sample_rate, audio_array = audio_data
        
        # ç¡®ä¿éŸ³é¢‘æ•°æ®æ˜¯æ­£ç¡®çš„æ ¼å¼
        if audio_array.dtype != np.int16:
            audio_array = (audio_array * 32767).astype(np.int16)
        
        # åˆ›å»ºWAVæ–‡ä»¶å­—èŠ‚æµ
        wav_buffer = io.BytesIO()
        with wave.open(wav_buffer, 'wb') as wav_file:
            wav_file.setnchannels(1)  # å•å£°é“
            wav_file.setsampwidth(2)  # 16ä½
            wav_file.setframerate(sample_rate)
            wav_file.writeframes(audio_array.tobytes())
        
        wav_buffer.seek(0)
        return wav_buffer.read()
    
    async def _transcribe_audio(self, audio_data: Tuple[int, np.ndarray]) -> str:
        """
        ä½¿ç”¨Geminiè¿›è¡Œè¯­éŸ³è½¬æ–‡å­—
        
        Args:
            audio_data: éŸ³é¢‘æ•°æ®
            
        Returns:
            è½¬å½•çš„æ–‡æœ¬
        """
        try:
            # å°†éŸ³é¢‘è½¬æ¢ä¸ºWAVæ ¼å¼
            wav_bytes = self._audio_to_wav_bytes(audio_data)
            
            # ä½¿ç”¨Geminiè¿›è¡Œè¯­éŸ³è½¬å½•
            # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨æ–‡æœ¬ç”Ÿæˆæ¨¡å‹é…åˆéŸ³é¢‘è¾“å…¥
            prompt = "è¯·è½¬å½•è¿™æ®µéŸ³é¢‘çš„å†…å®¹ï¼ˆå¯èƒ½ä¼šæœ‰é”™åˆ«å­—ï¼Œè¯·æ ¹æ®ä¸Šä¸‹æ–‡è¿›è¡Œä¿®æ­£ï¼‰ï¼š"
            
            # åˆ›å»ºéŸ³é¢‘éƒ¨åˆ†
            audio_part = {
                "mime_type": "audio/wav",
                "data": wav_bytes
            }
            
            # ç”Ÿæˆå“åº”
            response = await asyncio.to_thread(
                self.model.generate_content,
                [prompt, audio_part]
            )
            
            transcription = response.text.strip()
            logger.info(f"è¯­éŸ³è½¬å½•å®Œæˆ: {transcription}")
            return transcription
            
        except Exception as e:
            logger.error(f"è¯­éŸ³è½¬å½•å¤±è´¥: {e}")
            return ""
    
    async def _generate_response(self, user_input: str) -> str:
        """
        ç”ŸæˆAIå›å¤
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥æ–‡æœ¬
            
        Returns:
            AIå›å¤æ–‡æœ¬
        """
        try:
            # æ·»åŠ åˆ°å¯¹è¯å†å²
            self.chat_history.append({"role": "user", "content": user_input})
            
            # æ„å»ºå¯¹è¯ä¸Šä¸‹æ–‡
            context = "\n".join([
                f"{msg['role']}: {msg['content']}" 
                for msg in self.chat_history[-10:]  # ä¿ç•™æœ€è¿‘10è½®å¯¹è¯
            ])
            
            # ç”Ÿæˆå›å¤
            prompt = f"""ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ï¼Œæ­£åœ¨è¿›è¡Œè¯­éŸ³å¯¹è¯ã€‚è¯·æ ¹æ®ä»¥ä¸‹å¯¹è¯å†å²ç”Ÿæˆç®€æ´ã€è‡ªç„¶çš„å›å¤ï¼š

{context}

è¯·ç”¨ç®€æ´ã€å£è¯­åŒ–çš„æ–¹å¼å›å¤ï¼Œé€‚åˆè¯­éŸ³äº¤æµï¼š"""
            
            response = await asyncio.to_thread(
                self.model.generate_content,
                prompt
            )
            
            ai_response = response.text.strip()
            
            # æ·»åŠ åˆ°å¯¹è¯å†å²
            self.chat_history.append({"role": "assistant", "content": ai_response})
            
            logger.info(f"AIå›å¤ç”Ÿæˆ: {ai_response}")
            return ai_response
            
        except Exception as e:
            logger.error(f"AIå›å¤ç”Ÿæˆå¤±è´¥: {e}")
            return "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å›å¤ï¼Œè¯·ç¨åå†è¯•ã€‚"
    
    async def _text_to_speech(self, text: str) -> AsyncGenerator[Tuple[int, np.ndarray], None]:
        """
        æ–‡å­—è½¬è¯­éŸ³
        
        Args:
            text: è¦è½¬æ¢çš„æ–‡æœ¬
            
        Yields:
            éŸ³é¢‘æ•°æ®å—
        """
        try:
            # è¿™é‡Œä½¿ç”¨ç®€å•çš„TTSå®ç°
            # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¯ä»¥é›†æˆGoogle Cloud Text-to-Speechæˆ–å…¶ä»–TTSæœåŠ¡
            
            # æ¨¡æ‹ŸTTSè¾“å‡º - ç”Ÿæˆç®€å•çš„éŸ³é¢‘ä¿¡å·
            sample_rate = 16000
            duration = len(text) * 0.1  # æ ¹æ®æ–‡æœ¬é•¿åº¦ä¼°ç®—æ—¶é•¿
            
            # ç”Ÿæˆç®€å•çš„éŸ³é¢‘æ³¢å½¢ï¼ˆå®é™…åº”ç”¨ä¸­åº”è¯¥ä½¿ç”¨çœŸå®çš„TTSï¼‰
            t = np.linspace(0, duration, int(sample_rate * duration))
            frequency = 440  # A4éŸ³ç¬¦
            audio_signal = np.sin(2 * np.pi * frequency * t) * 0.3
            
            # è½¬æ¢ä¸º16ä½æ•´æ•°
            audio_int16 = (audio_signal * 32767).astype(np.int16)
            
            # åˆ†å—è¿”å›éŸ³é¢‘æ•°æ®
            chunk_size = sample_rate // 10  # 100ms chunks
            for i in range(0, len(audio_int16), chunk_size):
                chunk = audio_int16[i:i + chunk_size]
                if len(chunk) > 0:
                    yield (sample_rate, chunk.reshape(1, -1))
                    await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿå®æ—¶æ’­æ”¾
            
            logger.info(f"TTSå®Œæˆ: {text}")
            
        except Exception as e:
            logger.error(f"TTSå¤±è´¥: {e}")
    
    async def process_voice_input(self, audio_data: Tuple[int, np.ndarray]) -> AsyncGenerator[Tuple[int, np.ndarray], None]:
        """
        å¤„ç†è¯­éŸ³è¾“å…¥å¹¶ç”Ÿæˆè¯­éŸ³å›å¤
        
        Args:
            audio_data: è¾“å…¥çš„éŸ³é¢‘æ•°æ®
            
        Yields:
            å›å¤çš„éŸ³é¢‘æ•°æ®
        """
        try:
            logger.info("å¼€å§‹å¤„ç†è¯­éŸ³è¾“å…¥")
            
            # 1. è¯­éŸ³è½¬æ–‡å­—
            transcription = await self._transcribe_audio(audio_data)
            if not transcription:
                logger.warning("è¯­éŸ³è½¬å½•ä¸ºç©ºï¼Œè·³è¿‡å¤„ç†")
                return
            
            # 2. ç”ŸæˆAIå›å¤
            response_text = await self._generate_response(transcription)
            
            # 3. æ–‡å­—è½¬è¯­éŸ³å¹¶æµå¼è¿”å›
            async for audio_chunk in self._text_to_speech(response_text):
                yield audio_chunk
                
        except Exception as e:
            logger.error(f"è¯­éŸ³å¤„ç†å¤±è´¥: {e}")
            # è¿”å›é”™è¯¯æç¤ºéŸ³é¢‘
            error_message = "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯­éŸ³æ—¶å‡ºç°äº†é”™è¯¯ã€‚"
            async for audio_chunk in self._text_to_speech(error_message):
                yield audio_chunk


class VoiceChatStream:
    """
    è¯­éŸ³èŠå¤©æµå¤„ç†å™¨
    
    åŸºäºFastRTCçš„å®æ—¶è¯­éŸ³äº¤äº’æµ
    """
    
    def __init__(self, api_key: Optional[str] = None, model_name: Optional[str] = None):
        """
        åˆå§‹åŒ–è¯­éŸ³èŠå¤©æµ
        
        Args:
            api_key: Google AI APIå¯†é’¥
            model_name: Geminiæ¨¡å‹åç§°
        """
        self.gemini_client = GeminiVoiceChat(api_key, model_name)
        
        # åˆ›å»ºFastRTCæµ
        self.stream = Stream(
            handler=ReplyOnPause(self._handle_voice_input),
            modality="audio",
            mode="send-receive",
        )
        
        logger.info("è¯­éŸ³èŠå¤©æµåˆå§‹åŒ–å®Œæˆ")
    
    async def _handle_voice_input(self, audio_data: Tuple[int, np.ndarray]) -> AsyncGenerator[Tuple[int, np.ndarray], None]:
        """
        å¤„ç†è¯­éŸ³è¾“å…¥çš„å›è°ƒå‡½æ•°
        
        Args:
            audio_data: è¾“å…¥éŸ³é¢‘æ•°æ®
            
        Yields:
            å›å¤éŸ³é¢‘æ•°æ®
        """
        async for audio_chunk in self.gemini_client.process_voice_input(audio_data):
            yield audio_chunk
    
    def launch_ui(self, **kwargs):
        """
        å¯åŠ¨å†…ç½®UIç•Œé¢
        
        Args:
            **kwargs: ä¼ é€’ç»™stream.ui.launch()çš„å‚æ•°
        """
        logger.info("å¯åŠ¨è¯­éŸ³èŠå¤©UIç•Œé¢")
        return self.stream.ui.launch(**kwargs)
    
    def mount_to_app(self, app):
        """
        å°†è¯­éŸ³èŠå¤©æµæŒ‚è½½åˆ°FastAPIåº”ç”¨
        
        Args:
            app: FastAPIåº”ç”¨å®ä¾‹
        """
        logger.info("å°†è¯­éŸ³èŠå¤©æµæŒ‚è½½åˆ°FastAPIåº”ç”¨")
        return self.stream.mount(app)


def create_voice_chat_stream(api_key: Optional[str] = None, model_name: Optional[str] = None) -> VoiceChatStream:
    """
    åˆ›å»ºè¯­éŸ³èŠå¤©æµå®ä¾‹
    
    Args:
        api_key: Google AI APIå¯†é’¥
        model_name: Geminiæ¨¡å‹åç§°
        
    Returns:
        è¯­éŸ³èŠå¤©æµå®ä¾‹
    """
    return VoiceChatStream(api_key, model_name)


# ç‹¬ç«‹è¿è¡Œæ¨¡å—
if __name__ == "__main__":
    """
    ç‹¬ç«‹è¿è¡Œè¯­éŸ³èŠå¤©æ¨¡å—
    """
    import argparse
    
    parser = argparse.ArgumentParser(description="Geminiè¯­éŸ³èŠå¤©ç³»ç»Ÿ")
    parser.add_argument("--port", type=int, default=7860, help="æœåŠ¡ç«¯å£")
    parser.add_argument("--host", type=str, default="localhost", help="æœåŠ¡ä¸»æœº")
    parser.add_argument("--model", type=str, help="Geminiæ¨¡å‹åç§°")
    
    args = parser.parse_args()
    
    try:
        # åˆ›å»ºè¯­éŸ³èŠå¤©æµ
        voice_stream = create_voice_chat_stream(model_name=args.model)
        
        # å¯åŠ¨UI
        print(f"ğŸ¤ å¯åŠ¨Geminiè¯­éŸ³èŠå¤©ç³»ç»Ÿ...")
        print(f"ğŸ“¡ æœåŠ¡åœ°å€: http://{args.host}:{args.port}")
        print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {voice_stream.gemini_client.model_name}")
        print(f"ğŸ’¡ æç¤º: è¯´è¯åæš‚åœï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹å¹¶å›å¤")
        
        voice_stream.launch_ui(
            server_name=args.host,
            server_port=args.port,
            share=False
        )
        
    except Exception as e:
        logger.error(f"å¯åŠ¨å¤±è´¥: {e}")
        print(f"âŒ å¯åŠ¨å¤±è´¥: {e}")
        print("ğŸ’¡ è¯·æ£€æŸ¥:")
        print("   1. GEMINI_API_KEYç¯å¢ƒå˜é‡æ˜¯å¦è®¾ç½®")
        print("   2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        print("   3. ä¾èµ–åŒ…æ˜¯å¦æ­£ç¡®å®‰è£…") 