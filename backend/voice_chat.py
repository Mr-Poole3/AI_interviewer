"""
å®æ—¶è¯­éŸ³äº¤äº’æ¨¡å—

åŸºäºFastRTCå’ŒGoogle Geminiè¯­éŸ³APIçš„å®æ—¶è¯­éŸ³å¯¹è¯ç³»ç»Ÿ
æ”¯æŒè¯­éŸ³è¾“å…¥ã€æš‚åœæ£€æµ‹ã€å®æ—¶å“åº”å’Œè¯­éŸ³è¾“å‡º
"""
import logging
import asyncio
from typing import Optional, AsyncGenerator, Tuple
import numpy as np
import google.generativeai as genai
from fastrtc import Stream, ReplyOnPause, audio_to_bytes, aggregate_bytes_to_16bit, get_tts_model
import io
import wave

# å¯¼å…¥é¡¹ç›®é…ç½®
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config import get_GEMINI_API_KEY, get_gemini_model

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class GeminiVoiceChat:
    """
    Geminiè¯­éŸ³èŠå¤©å®¢æˆ·ç«¯
    
    æä¾›å®æ—¶è¯­éŸ³äº¤äº’åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
    - è¯­éŸ³è½¬æ–‡å­—ï¼ˆé€šè¿‡Gemini Live APIï¼‰
    - æ™ºèƒ½å¯¹è¯ç”Ÿæˆ
    - æ–‡å­—è½¬è¯­éŸ³è¾“å‡ºï¼ˆä½¿ç”¨FastRTC TTSï¼‰
    - è‡ªåŠ¨æš‚åœæ£€æµ‹
    """
    
    def __init__(self, api_key: Optional[str] = None, model_name: Optional[str] = None):
        """
        åˆå§‹åŒ–Geminiè¯­éŸ³èŠå¤©å®¢æˆ·ç«¯
        
        Args:
            api_key: Google AI APIå¯†é’¥
            model_name: Geminiæ¨¡å‹åç§°
        """
        self.api_key = api_key or get_GEMINI_API_KEY()
        self.model_name = model_name or get_gemini_model()
        
        if not self.api_key:
            raise ValueError("Google AI APIå¯†é’¥æœªè®¾ç½®ï¼Œè¯·è®¾ç½®GEMINI_API_KEYç¯å¢ƒå˜é‡")
        
        # é…ç½®Google AI
        genai.configure(api_key=self.api_key)
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = genai.GenerativeModel(self.model_name)
        
        # åˆå§‹åŒ–FastRTC TTSæ¨¡å‹
        try:
            self.tts_model = get_tts_model()
            logger.info("FastRTC TTSæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"FastRTC TTSæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            self.tts_model = None
        
        # å¯¹è¯å†å²
        self.chat_history = []
        
        logger.info(f"Geminiè¯­éŸ³èŠå¤©å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆï¼Œæ¨¡å‹: {self.model_name}")
    
    def _audio_to_wav_bytes(self, audio_data: Tuple[int, np.ndarray]) -> bytes:
        """
        å°†éŸ³é¢‘æ•°æ®è½¬æ¢ä¸ºWAVæ ¼å¼å­—èŠ‚æµ
        
        Args:
            audio_data: (é‡‡æ ·ç‡, éŸ³é¢‘æ•°ç»„) å…ƒç»„
            
        Returns:
            WAVæ ¼å¼çš„å­—èŠ‚æµ
        """
        sample_rate, audio_array = audio_data
        
        # ç¡®ä¿éŸ³é¢‘æ•°æ®æ˜¯æ­£ç¡®çš„æ ¼å¼
        if audio_array.dtype != np.int16:
            audio_array = (audio_array * 32767).astype(np.int16)
        
        # åˆ›å»ºWAVæ–‡ä»¶å­—èŠ‚æµ
        wav_buffer = io.BytesIO()
        with wave.open(wav_buffer, 'wb') as wav_file:
            wav_file.setnchannels(1)  # å•å£°é“
            wav_file.setsampwidth(2)  # 16ä½
            wav_file.setframerate(sample_rate)
            wav_file.writeframes(audio_array.tobytes())
        
        wav_buffer.seek(0)
        return wav_buffer.read()
    
    async def _transcribe_audio(self, audio_data: Tuple[int, np.ndarray]) -> str:
        """
        ä½¿ç”¨Geminiè¿›è¡Œè¯­éŸ³è½¬æ–‡å­—
        
        Args:
            audio_data: éŸ³é¢‘æ•°æ®
            
        Returns:
            è½¬å½•çš„æ–‡æœ¬
        """
        try:
            # å°†éŸ³é¢‘è½¬æ¢ä¸ºWAVæ ¼å¼
            wav_bytes = self._audio_to_wav_bytes(audio_data)
            
            # ä½¿ç”¨Geminiè¿›è¡Œè¯­éŸ³è½¬å½•
            # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨æ–‡æœ¬ç”Ÿæˆæ¨¡å‹é…åˆéŸ³é¢‘è¾“å…¥
            prompt = "è¯·è½¬å½•è¿™æ®µéŸ³é¢‘çš„å†…å®¹ï¼ˆå¯èƒ½ä¼šæœ‰é”™åˆ«å­—ï¼Œè¯·æ ¹æ®ä¸Šä¸‹æ–‡è¿›è¡Œä¿®æ­£ï¼‰ï¼š"
            
            # åˆ›å»ºéŸ³é¢‘éƒ¨åˆ†
            audio_part = {
                "mime_type": "audio/wav",
                "data": wav_bytes
            }
            
            # ç”Ÿæˆå“åº”
            response = await asyncio.to_thread(
                self.model.generate_content,
                [prompt, audio_part]
            )
            
            transcription = response.text.strip()
            logger.info(f"è¯­éŸ³è½¬å½•å®Œæˆ: {transcription}")
            return transcription
            
        except Exception as e:
            logger.error(f"è¯­éŸ³è½¬å½•å¤±è´¥: {e}")
            return ""
    
    async def _generate_response(self, user_input: str) -> str:
        """
        ç”ŸæˆAIå›å¤
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥æ–‡æœ¬
            
        Returns:
            AIå›å¤æ–‡æœ¬
        """
        try:
            # æ·»åŠ åˆ°å¯¹è¯å†å²
            self.chat_history.append({"role": "user", "content": user_input})
            
            # æ„å»ºå¯¹è¯ä¸Šä¸‹æ–‡
            context = "\n".join([
                f"{msg['role']}: {msg['content']}" 
                for msg in self.chat_history[-10:]  # ä¿ç•™æœ€è¿‘10è½®å¯¹è¯
            ])
            
            # ç”Ÿæˆå›å¤
            prompt = f"""ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ï¼Œæ­£åœ¨è¿›è¡Œè¯­éŸ³å¯¹è¯ã€‚è¯·æ ¹æ®ä»¥ä¸‹å¯¹è¯å†å²ç”Ÿæˆç®€æ´ã€è‡ªç„¶çš„å›å¤ï¼š

{context}

è¯·ç”¨ç®€æ´ã€å£è¯­åŒ–çš„æ–¹å¼å›å¤ï¼Œé€‚åˆè¯­éŸ³äº¤æµï¼š"""
            
            response = await asyncio.to_thread(
                self.model.generate_content,
                prompt
            )
            
            ai_response = response.text.strip()
            
            # æ·»åŠ åˆ°å¯¹è¯å†å²
            self.chat_history.append({"role": "assistant", "content": ai_response})
            
            logger.info(f"AIå›å¤ç”Ÿæˆ: {ai_response}")
            return ai_response
            
        except Exception as e:
            logger.error(f"AIå›å¤ç”Ÿæˆå¤±è´¥: {e}")
            return "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å›å¤ï¼Œè¯·ç¨åå†è¯•ã€‚"
    
    async def _text_to_speech(self, text: str) -> AsyncGenerator[Tuple[int, np.ndarray], None]:
        """
        æ–‡å­—è½¬è¯­éŸ³ - ä½¿ç”¨FastRTC TTS
        
        Args:
            text: è¦è½¬æ¢çš„æ–‡æœ¬
            
        Yields:
            éŸ³é¢‘æ•°æ®å— (sample_rate, audio_array)
        """
        try:
            if not self.tts_model:
                logger.error("TTSæ¨¡å‹æœªåˆå§‹åŒ–ï¼Œæ— æ³•è¿›è¡Œè¯­éŸ³åˆæˆ")
                return
            
            logger.info(f"å¼€å§‹TTSè½¬æ¢: {text[:50]}...")
            
            # ä½¿ç”¨FastRTCçš„æµå¼TTS
            async for audio_chunk in self.tts_model.stream_tts(text):
                # FastRTCè¿”å›çš„éŸ³é¢‘æ ¼å¼å¯èƒ½éœ€è¦è½¬æ¢
                if isinstance(audio_chunk, tuple) and len(audio_chunk) == 2:
                    # å¦‚æœå·²ç»æ˜¯(sample_rate, audio_array)æ ¼å¼
                    yield audio_chunk
                else:
                    # å¦‚æœæ˜¯å…¶ä»–æ ¼å¼ï¼Œéœ€è¦è½¬æ¢
                    # å‡è®¾è¿”å›çš„æ˜¯16kHzçš„éŸ³é¢‘æ•°æ®
                    sample_rate = 16000
                    if isinstance(audio_chunk, np.ndarray):
                        yield (sample_rate, audio_chunk)
                    else:
                        # è½¬æ¢ä¸ºnumpyæ•°ç»„
                        audio_array = np.array(audio_chunk, dtype=np.float32)
                        # ç¡®ä¿æ˜¯æ­£ç¡®çš„å½¢çŠ¶
                        if audio_array.ndim == 1:
                            audio_array = audio_array.reshape(1, -1)
                        yield (sample_rate, audio_array)
            
            logger.info(f"TTSè½¬æ¢å®Œæˆ: {text[:50]}...")
            
        except Exception as e:
            logger.error(f"FastRTC TTSè½¬æ¢å¤±è´¥: {e}")
            # é™çº§åˆ°ç®€å•çš„é”™è¯¯æç¤ºéŸ³é¢‘
            try:
                sample_rate = 16000
                duration = 1.0  # 1ç§’é”™è¯¯æç¤ºéŸ³
                t = np.linspace(0, duration, int(sample_rate * duration))
                # ç”Ÿæˆç®€å•çš„æç¤ºéŸ³ï¼ˆä¸¤ä¸ªéŸ³è°ƒï¼‰
                frequency1, frequency2 = 800, 400
                audio_signal = (np.sin(2 * np.pi * frequency1 * t[:len(t)//2]) * 0.3 + 
                               np.sin(2 * np.pi * frequency2 * t[len(t)//2:]) * 0.3)
                
                # è½¬æ¢ä¸ºæ­£ç¡®æ ¼å¼
                audio_array = audio_signal.astype(np.float32).reshape(1, -1)
                yield (sample_rate, audio_array)
                
            except Exception as fallback_error:
                logger.error(f"é”™è¯¯æç¤ºéŸ³ç”Ÿæˆä¹Ÿå¤±è´¥: {fallback_error}")
    
    async def process_voice_input(self, audio_data: Tuple[int, np.ndarray]) -> AsyncGenerator[Tuple[int, np.ndarray], None]:
        """
        å¤„ç†è¯­éŸ³è¾“å…¥å¹¶ç”Ÿæˆè¯­éŸ³å›å¤
        
        Args:
            audio_data: è¾“å…¥çš„éŸ³é¢‘æ•°æ®
            
        Yields:
            å›å¤çš„éŸ³é¢‘æ•°æ®
        """
        try:
            logger.info("å¼€å§‹å¤„ç†è¯­éŸ³è¾“å…¥")
            
            # 1. è¯­éŸ³è½¬æ–‡å­—
            transcription = await self._transcribe_audio(audio_data)
            if not transcription:
                logger.warning("è¯­éŸ³è½¬å½•ä¸ºç©ºï¼Œè·³è¿‡å¤„ç†")
                return
            
            # 2. ç”ŸæˆAIå›å¤
            response_text = await self._generate_response(transcription)
            
            # 3. æ–‡å­—è½¬è¯­éŸ³å¹¶æµå¼è¿”å›
            async for audio_chunk in self._text_to_speech(response_text):
                yield audio_chunk
                
        except Exception as e:
            logger.error(f"è¯­éŸ³å¤„ç†å¤±è´¥: {e}")
            # è¿”å›é”™è¯¯æç¤ºéŸ³é¢‘
            error_message = "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯­éŸ³æ—¶å‡ºç°äº†é”™è¯¯ã€‚"
            async for audio_chunk in self._text_to_speech(error_message):
                yield audio_chunk


class VoiceChatStream:
    """
    è¯­éŸ³èŠå¤©æµå¤„ç†å™¨
    
    åŸºäºFastRTCçš„å®æ—¶è¯­éŸ³äº¤äº’æµ
    """
    
    def __init__(self, api_key: Optional[str] = None, model_name: Optional[str] = None):
        """
        åˆå§‹åŒ–è¯­éŸ³èŠå¤©æµ
        
        Args:
            api_key: Google AI APIå¯†é’¥
            model_name: Geminiæ¨¡å‹åç§°
        """
        self.gemini_client = GeminiVoiceChat(api_key, model_name)
        
        # åˆ›å»ºFastRTCæµ
        self.stream = Stream(
            handler=ReplyOnPause(self._handle_voice_input),
            modality="audio",
            mode="send-receive",
        )
        
        logger.info("è¯­éŸ³èŠå¤©æµåˆå§‹åŒ–å®Œæˆ")
    
    async def _handle_voice_input(self, audio_data: Tuple[int, np.ndarray]) -> AsyncGenerator[Tuple[int, np.ndarray], None]:
        """
        å¤„ç†è¯­éŸ³è¾“å…¥çš„å›è°ƒå‡½æ•°
        
        Args:
            audio_data: è¾“å…¥éŸ³é¢‘æ•°æ®
            
        Yields:
            å›å¤éŸ³é¢‘æ•°æ®
        """
        async for audio_chunk in self.gemini_client.process_voice_input(audio_data):
            yield audio_chunk
    
    def launch_ui(self, **kwargs):
        """
        å¯åŠ¨å†…ç½®UIç•Œé¢
        
        Args:
            **kwargs: ä¼ é€’ç»™stream.ui.launch()çš„å‚æ•°
        """
        logger.info("å¯åŠ¨è¯­éŸ³èŠå¤©UIç•Œé¢")
        return self.stream.ui.launch(**kwargs)
    
    def mount_to_app(self, app):
        """
        å°†è¯­éŸ³èŠå¤©æµæŒ‚è½½åˆ°FastAPIåº”ç”¨
        
        Args:
            app: FastAPIåº”ç”¨å®ä¾‹
        """
        logger.info("å°†è¯­éŸ³èŠå¤©æµæŒ‚è½½åˆ°FastAPIåº”ç”¨")
        return self.stream.mount(app)


def create_voice_chat_stream(api_key: Optional[str] = None, model_name: Optional[str] = None) -> VoiceChatStream:
    """
    åˆ›å»ºè¯­éŸ³èŠå¤©æµå®ä¾‹
    
    Args:
        api_key: Google AI APIå¯†é’¥
        model_name: Geminiæ¨¡å‹åç§°
        
    Returns:
        è¯­éŸ³èŠå¤©æµå®ä¾‹
    """
    return VoiceChatStream(api_key, model_name)


# ç‹¬ç«‹è¿è¡Œæ¨¡å—
if __name__ == "__main__":
    """
    ç‹¬ç«‹è¿è¡Œè¯­éŸ³èŠå¤©æ¨¡å—
    """
    import argparse
    
    parser = argparse.ArgumentParser(description="Geminiè¯­éŸ³èŠå¤©ç³»ç»Ÿ")
    parser.add_argument("--port", type=int, default=7860, help="æœåŠ¡ç«¯å£")
    parser.add_argument("--host", type=str, default="localhost", help="æœåŠ¡ä¸»æœº")
    parser.add_argument("--model", type=str, help="Geminiæ¨¡å‹åç§°")
    
    args = parser.parse_args()
    
    try:
        # åˆ›å»ºè¯­éŸ³èŠå¤©æµ
        voice_stream = create_voice_chat_stream(model_name=args.model)
        
        # å¯åŠ¨UI
        print(f"ğŸ¤ å¯åŠ¨Geminiè¯­éŸ³èŠå¤©ç³»ç»Ÿ...")
        print(f"ğŸ“¡ æœåŠ¡åœ°å€: http://{args.host}:{args.port}")
        print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {voice_stream.gemini_client.model_name}")
        print(f"ğŸ’¡ æç¤º: è¯´è¯åæš‚åœï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹å¹¶å›å¤")
        
        voice_stream.launch_ui(
            server_name=args.host,
            server_port=args.port,
            share=False
        )
        
    except Exception as e:
        logger.error(f"å¯åŠ¨å¤±è´¥: {e}")
        print(f"âŒ å¯åŠ¨å¤±è´¥: {e}")
        print("ğŸ’¡ è¯·æ£€æŸ¥:")
        print("   1. GEMINI_API_KEYç¯å¢ƒå˜é‡æ˜¯å¦è®¾ç½®")
        print("   2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        print("   3. ä¾èµ–åŒ…æ˜¯å¦æ­£ç¡®å®‰è£…") 